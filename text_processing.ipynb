{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated by: Kristen McGarry, EDO Data Analyst Intern\\nDate: July 2017\\nLast Updated: July 27, 2017\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Created by: Kristen McGarry, EDO Data Analyst Intern\n",
    "Date: July 2017\n",
    "Last Updated: July 27, 2017\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import codecs\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE HTML TAGS\n",
    "\n",
    "def cleanhtml(raw_html,outFile):\n",
    "    table_cleaner = re.compile('(?i)<table.*?</table>')\n",
    "    regexs = [table_cleaner, '<.*?>', '\\n', '\\t', '&nbsp', '&#']\n",
    "    for regex in regexs:\n",
    "        raw_html = re.sub(regex, ' ', raw_html)\n",
    "\n",
    "    raw_html = raw_html.replace(\";\",\" \")\n",
    "        \n",
    "    out_file = open(outFile,\"w\")\n",
    "    out_file.write(raw_html)\n",
    "    out_file.close()\n",
    "    \n",
    "    return \"done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE NON-ASCII CHARACTERS\n",
    "\n",
    "def onlyAscii(inFile,outFile):\n",
    "    ip=open(inFile,'r')\n",
    "    op=open(outFile,'w')\n",
    "    for line in ip:\n",
    "        line=line.strip().decode(\"ascii\",\"ignore\").encode(\"ascii\")\n",
    "        whitespace = \"\\r\\n\\t\"\n",
    "        line = line.strip(whitespace)\n",
    "        if line==\"\":continue\n",
    "        op.write(line)\n",
    "    ip.close()\n",
    "    op.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ IN TEXT WITH REMOVED TAGS AND NON-ASCII CHARACTERS\n",
    "\n",
    "def getText(inFile):\n",
    "    i_file = open(inFile,'r')\n",
    "    text = i_file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE STOP WORDS\n",
    "\n",
    "def removeStopWords(text):\n",
    "    stop = (stopwords.words('english')) + (list(string.punctuation))\n",
    "\n",
    "    clean_text = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    for word in tokens:\n",
    "        if word not in stop:\n",
    "            clean_text.append(word)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORD FREQUENCY\n",
    "\n",
    "def wordFrequency(clean_text):\n",
    "    freq_dict = {}\n",
    "\n",
    "    for word in clean_text:\n",
    "        if word in freq_dict:\n",
    "            freq_dict[word] = freq_dict[word] + 1\n",
    "        else:\n",
    "            freq_dict[word] =1\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SORT WORD FREQUENCY IN DESCENDING ORDER\n",
    "\n",
    "def sortWordFreq(freq_dict):\n",
    "    \n",
    "    top_value = 0\n",
    "    top_word = \"\"\n",
    "    mybool = True\n",
    "    \n",
    "    while mybool == True:\n",
    "        for word in freq_dict.keys():\n",
    "            value = freq_dict[word]\n",
    "            if value > top_value:\n",
    "                top_value = value\n",
    "                top_word = word\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        print (top_word + \": \" + str(top_value))\n",
    "        \n",
    "        del freq_dict[top_word]\n",
    "        top_value = 0\n",
    "        top_word = \"\"\n",
    "        \n",
    "        if (len(freq_dict.keys()) == 0):\n",
    "            mybool = False\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SENTENCE TOKENIZER\n",
    "\n",
    "def tokenizer(text):\n",
    "    sent_tokens = nltk.sent_tokenize(text)\n",
    "    return sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART OF SPEECH (POS) TAGGER\n",
    "\n",
    "def posTagger(sent_tokens):\n",
    "    pos_text = []\n",
    "\n",
    "    for i in range(0,(len(sent_tokens))):\n",
    "        word_tokens = word_tokenize(sent_tokens[i])\n",
    "        pos_temp = nltk.pos_tag(word_tokens)\n",
    "        pos_text.append(pos_temp)\n",
    "    return pos_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXTRACT CERTAIN POS TAGS\n",
    "\n",
    "def cleanPosTagger(pos_tags):\n",
    "    #key_tags = [\"CD\",\"NNP\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]\n",
    "    key_tags = [\"NNP\"]\n",
    "    key_text = \"\"\n",
    "    key_text_tags = []\n",
    "    \n",
    "    for sent in pos_tags:\n",
    "        for word_tag in sent:\n",
    "            if word_tag[1] in key_tags:\n",
    "                if word_tag[0] != \"|\":\n",
    "                    key_text_tags += word_tag\n",
    "                    key_text = key_text + word_tag[0] + \" \"\n",
    "    return key_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE REPEATING WORDS (i.e. board board directors)\n",
    "\n",
    "def removeRepeats(key_text):\n",
    "    text = \"\"\n",
    "    words = key_text.split(\" \")\n",
    "    for i in range(0,len(words)-1):\n",
    "        if len(words[i]) > 2:\n",
    "            if words[i] != words[i+1]:\n",
    "                text =  text + \" \" + words[i]\n",
    "        else:\n",
    "            continue\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEO4J CYPHER COMMANDS\n",
    "\n",
    "def neo4j(key_tag_text, list_directors,cypher_file):\n",
    "    out_file = open(cypher_file,\"w\")\n",
    "    \n",
    "    create_words = ('WITH split(tolower(\"' + key_tag_text + '\"),\" \") AS text UNWIND range(0,size(text)-2) AS i MERGE(w1:Word {name :text[i]}) ON CREATE SET w1.count = 1 ON MATCH SET w1.count = w1.count + 1 MERGE(w2:Word {name :text[i+1]}) ON CREATE SET w2.count = 1 ON MATCH SET w2.count = w2.count + 1 MERGE(w1)-[r:NEXT]->(w2) ON CREATE SET r.count = 1 ON MATCH SET r.count = r.count + 1;')\n",
    "    out_file.write(create_words)\n",
    "    out_file.write('\\n')\n",
    "    \n",
    "    # HARD CODED TO APPLE DOC\n",
    "    create_doc = 'CREATE (Apple14A:Document{title:\"Apple Inc. Notice of 2017 Annual Meeing of Shareholders and Proxy Statement\", type:\"14A\", date:\"2017-02-28\", source:\"SEC EDGAR\"});'\n",
    "    out_file.write(create_doc)\n",
    "    out_file.write('\\n')\n",
    "    \n",
    "    for director in list_directors:\n",
    "        names = director.split(\" \")\n",
    "        for name in names:\n",
    "            name = name.lower()\n",
    "            if len(name) > 2: \n",
    "                add_person_label = 'MATCH (' + name + ':Word) WHERE ' + name + '.name = \"' + name + '\" SET ' + name + ':Person;'\n",
    "                out_file.write(add_person_label)\n",
    "                out_file.write('\\n')\n",
    "                \n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_file = open(\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph.htm\",\"r\")\n",
    "raw_html = in_file.read()\n",
    "cleanhtml(raw_html,\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "board: 44\n",
      "executive: 28\n",
      "company: 27\n",
      "apple: 25\n",
      "chief: 23\n",
      "officer: 23\n",
      "served: 23\n",
      "experience: 20\n",
      "directors: 20\n",
      "committee: 19\n",
      "inc.: 19\n",
      "proxy: 18\n",
      "since: 17\n",
      "public: 16\n",
      "146: 16\n",
      "chairman: 15\n",
      "directorships: 14\n",
      "president: 14\n",
      "financial: 14\n",
      "nominating: 14\n",
      "years: 13\n",
      "mr.: 12\n",
      "director: 12\n",
      "access: 11\n",
      "management: 10\n",
      "leadership: 10\n",
      "international: 9\n",
      "shareholders: 9\n",
      "among: 9\n",
      "vice: 9\n",
      "business: 8\n",
      "brings: 8\n",
      "including: 8\n",
      "service: 8\n",
      "candidates: 8\n",
      "qualifications: 8\n",
      "old: 8\n",
      "trustees: 7\n",
      "corporate: 7\n",
      "cook: 6\n",
      "large: 6\n",
      "selected: 6\n",
      "ms.: 6\n",
      "149: 6\n",
      "2017: 6\n",
      "statement: 6\n",
      "memberships: 6\n",
      "current: 6\n",
      "blackrock: 6\n",
      "nominees: 6\n",
      "amp: 6\n",
      "extensive: 6\n",
      "shareholder: 6\n",
      "operating: 6\n",
      "2000: 6\n",
      "global: 5\n",
      "shares: 5\n",
      "dr.: 5\n",
      "along: 5\n",
      "september: 5\n",
      "2012: 5\n",
      "contents: 5\n",
      "senior: 5\n",
      "sugar: 5\n",
      "wagner: 5\n",
      "avon: 5\n",
      "april: 5\n",
      "bell: 5\n",
      "table: 5\n",
      "member: 5\n",
      "jung: 5\n",
      "previously: 5\n",
      "gore: 5\n",
      "expertise: 5\n",
      "positions: 4\n",
      "1998: 4\n",
      "products: 4\n",
      "governance: 4\n",
      "council: 4\n",
      "operations: 4\n",
      "university: 4\n",
      "members: 4\n",
      "nominate: 4\n",
      "also: 4\n",
      "worldwide: 4\n",
      "levinson: 4\n",
      "advisory: 4\n",
      "disney: 4\n",
      "former: 4\n",
      "audit: 4\n",
      "five: 4\n",
      "iger: 4\n",
      "corporation: 4\n",
      "chair: 3\n",
      "skills: 3\n",
      "perspective: 3\n",
      "two: 3\n",
      "1999: 3\n",
      "december: 3\n",
      "information: 3\n",
      "boeing: 3\n",
      "held: 3\n",
      "group: 3\n",
      "2011: 3\n",
      "days: 3\n",
      "compensation: 3\n",
      "officers: 3\n",
      "capital: 3\n",
      "national: 3\n",
      "last: 3\n",
      "walt: 3\n",
      "68: 3\n",
      "considers: 3\n",
      "2012.: 3\n",
      "firm: 3\n",
      "institute: 3\n",
      "technology: 3\n",
      "center: 3\n",
      "recommended: 3\n",
      "loaned: 3\n",
      "january: 3\n",
      "bylaws: 3\n",
      "marketing: 3\n",
      "boards: 3\n",
      "support: 3\n",
      "brand: 3\n",
      "sales: 3\n",
      "diverse: 3\n",
      "2003: 3\n",
      "2008: 3\n",
      "ron: 2\n",
      "include: 2\n",
      "companies: 2\n",
      "llc: 2\n",
      "investment: 2\n",
      "sue: 2\n",
      "abc: 2\n",
      "increasing: 2\n",
      "led: 2\n",
      "understanding: 2\n",
      "genomics: 2\n",
      "asset: 2\n",
      "organizations: 2\n",
      "rights: 2\n",
      "recall: 2\n",
      "example: 2\n",
      "f.: 2\n",
      "provide: 2\n",
      "147: 2\n",
      "may: 2\n",
      "needs: 2\n",
      "148: 2\n",
      "responsibility: 2\n",
      "2015: 2\n",
      "2014: 2\n",
      "finance: 2\n",
      "james: 2\n",
      "series: 2\n",
      "research: 2\n",
      "2005.: 2\n",
      "u.s.: 2\n",
      "california: 2\n",
      "times: 2\n",
      "american: 2\n",
      "nonprofit: 2\n",
      "number: 2\n",
      "strategic: 2\n",
      "least: 2\n",
      "adopted: 2\n",
      "academy: 2\n",
      "july: 2\n",
      "venture: 2\n",
      "qualities: 2\n",
      "significant: 2\n",
      "america: 2\n",
      "medical: 2\n",
      "planning: 2\n",
      "art: 2\n",
      "college: 2\n",
      "20: 2\n",
      "annual: 2\n",
      "attributes: 2\n",
      "businesses: 2\n",
      "66: 2\n",
      "perspectives: 2\n",
      "addition: 2\n",
      "meeting: 2\n",
      "al: 2\n",
      "andrea: 2\n",
      "2010: 2\n",
      "evaluating: 2\n",
      "memorial: 2\n",
      "bob: 2\n",
      "retired: 2\n",
      "candidate: 2\n",
      "march: 2\n",
      "serves: 2\n",
      "northrop: 2\n",
      "provided: 2\n",
      "industry: 2\n",
      "within: 2\n",
      "2003.: 2\n",
      "grumman: 2\n",
      "october: 2\n",
      "amendments: 2\n",
      "tim: 2\n",
      "genentech: 2\n",
      "longer: 2\n",
      "2002: 2\n",
      "2001: 2\n",
      "represent: 1\n",
      "limited: 1\n",
      "four: 1\n",
      "deadline: 1\n",
      "consists: 1\n",
      "risk: 1\n",
      "jpmorgan: 1\n",
      "philanthropic: 1\n",
      "school: 1\n",
      "level: 1\n",
      "joined: 1\n",
      "cdw: 1\n",
      "enhance: 1\n",
      "trw: 1\n",
      "lewis-sigler: 1\n",
      "leaders: 1\n",
      "ten: 1\n",
      "air: 1\n",
      "section: 1\n",
      "amyris: 1\n",
      "practices: 1\n",
      "exercise: 1\n",
      "multinational: 1\n",
      "deemed: 1\n",
      "focused: 1\n",
      "groups: 1\n",
      "address: 1\n",
      "interpret: 1\n",
      "search: 1\n",
      "engage: 1\n",
      "biographies: 1\n",
      "compliance: 1\n",
      "prior: 1\n",
      "women: 1\n",
      "implement: 1\n",
      "regardless: 1\n",
      "2013.: 1\n",
      "highly: 1\n",
      "operational: 1\n",
      "circumstances: 1\n",
      "criteria: 1\n",
      "scope: 1\n",
      "caufield: 1\n",
      "particular: 1\n",
      "hold: 1\n",
      "kettering: 1\n",
      "must: 1\n",
      "1992: 1\n",
      "1995: 1\n",
      "byers: 1\n",
      "states: 1\n",
      "effectively: 1\n",
      "americas: 1\n",
      "respective: 1\n",
      "united: 1\n",
      "requirements: 1\n",
      "chemical: 1\n",
      "stock: 1\n",
      "minority: 1\n",
      "aging: 1\n",
      "southern: 1\n",
      "biographical: 1\n",
      "media: 1\n",
      "subsequently: 1\n",
      "serving: 1\n",
      "microfinance: 1\n",
      "committed: 1\n",
      "november: 1\n",
      "developer: 1\n",
      "industries: 1\n",
      "sciences: 1\n",
      "chosen: 1\n",
      "hackley: 1\n",
      "biomedical: 1\n",
      "2016: 1\n",
      "easier: 1\n",
      "seeking: 1\n",
      "framework: 1\n",
      "qualified: 1\n",
      "perkins: 1\n",
      "hall: 1\n",
      "association: 1\n",
      "literacy: 1\n",
      "identified: 1\n",
      "economy: 1\n",
      "violations: 1\n",
      "generation: 1\n",
      "year: 1\n",
      "network: 1\n",
      "robert: 1\n",
      "integrative: 1\n",
      "health: 1\n",
      "co-founder: 1\n",
      "sloan: 1\n",
      "independence: 1\n",
      "foundation: 1\n",
      "reporting: 1\n",
      "philharmonic: 1\n",
      "personal: 1\n",
      "advisor: 1\n",
      "regulatory: 1\n",
      "daimler: 1\n",
      "care: 1\n",
      "retained: 1\n",
      "museum: 1\n",
      "major: 1\n",
      "industrial: 1\n",
      "bloomberg: 1\n",
      "cfo: 1\n",
      "chevron: 1\n",
      "owning: 1\n",
      "girls: 1\n",
      "roche: 1\n",
      "amgen: 1\n",
      "molecular: 1\n",
      "lease: 1\n",
      "interests: 1\n",
      "diversified: 1\n",
      "environmental: 1\n",
      "believe: 1\n",
      "representing: 1\n",
      "11: 1\n",
      "13: 1\n",
      "15: 1\n",
      "14: 1\n",
      "17: 1\n",
      "princeton: 1\n",
      "limiting: 1\n",
      "project: 1\n",
      "nominee: 1\n",
      "outstanding: 1\n",
      "kennedy: 1\n",
      "client: 1\n",
      "potential: 1\n",
      "mit: 1\n",
      "tenure: 1\n",
      "indemnification: 1\n",
      "eight: 1\n",
      "organization: 1\n",
      "services: 1\n",
      "co-chairman: 1\n",
      "consumer: 1\n",
      "institutions: 1\n",
      "obligations: 1\n",
      "supported: 1\n",
      "nominated: 1\n",
      "litton: 1\n",
      "bring: 1\n",
      "well-being: 1\n",
      "availability: 1\n",
      "bain: 1\n",
      "justice: 1\n",
      "unilaterally: 1\n",
      "third-party: 1\n",
      "predecessor: 1\n",
      "valuable: 1\n",
      "clubs: 1\n",
      "new: 1\n",
      "committees: 1\n",
      "fields: 1\n",
      "16: 1\n",
      "18: 1\n",
      "satisfy: 1\n",
      "evolving: 1\n",
      "elected: 1\n",
      "actively: 1\n",
      "calendar: 1\n",
      "best: 1\n",
      "ability: 1\n",
      "currently: 1\n",
      "representatives: 1\n",
      "3: 1\n",
      "various: 1\n",
      "previous: 1\n",
      "co.: 1\n",
      "g100: 1\n",
      "notice: 1\n",
      "terms: 1\n",
      "august: 1\n",
      "harvard: 1\n",
      "received: 1\n",
      "climate: 1\n",
      "many: 1\n",
      "drug: 1\n",
      "context: 1\n",
      "cancer: 1\n",
      "color: 1\n",
      "narrowed: 1\n",
      "panel: 1\n",
      "50.: 1\n",
      "arts: 1\n",
      "three: 1\n",
      "strategy: 1\n",
      "temasek: 1\n",
      "partnership: 1\n",
      "diversity: 1\n",
      "policy: 1\n",
      "controller: 1\n",
      "sound: 1\n",
      "re-nominate: 1\n",
      "evaluates: 1\n",
      "politics: 1\n",
      "partner: 1\n",
      "fame: 1\n",
      "chase: 1\n",
      "nike: 1\n",
      "things: 1\n",
      "make: 1\n",
      "complex: 1\n",
      "incumbent: 1\n",
      "2005: 1\n",
      "development: 1\n",
      "extended: 1\n",
      "u.s.-china: 1\n",
      "assist: 1\n",
      "persons: 1\n",
      "ownership: 1\n",
      "aggregate: 1\n",
      "judgment: 1\n",
      "1974: 1\n",
      "well: 1\n",
      "academic: 1\n",
      "materials: 1\n",
      "ltd.: 1\n",
      "swiss: 1\n",
      "quantitative: 1\n",
      "arising: 1\n",
      "investments: 1\n",
      "cities/abc: 1\n",
      "background: 1\n",
      "domestic: 1\n",
      "actions: 1\n",
      "human: 1\n",
      "alternative: 1\n",
      "2000.: 1\n",
      "acumen: 1\n",
      "character: 1\n",
      "2007.: 1\n",
      "hoffman-la: 1\n",
      "increased: 1\n",
      "provisions: 1\n",
      "possible: 1\n",
      "aerospace: 1\n",
      "using: 1\n",
      "unique: 1\n",
      "advanced: 1\n",
      "58: 1\n",
      "identifying: 1\n",
      "55: 1\n",
      "reduces: 1\n",
      "56: 1\n",
      "philanthropies: 1\n",
      "communications: 1\n",
      "continue: 1\n",
      "security: 1\n",
      "reduced: 1\n",
      "senate: 1\n",
      "consultants: 1\n",
      "trends: 1\n",
      "export: 1\n",
      "electric: 1\n",
      "broad: 1\n",
      "legal: 1\n",
      "kleiner: 1\n",
      "individuals: 1\n",
      "discretion: 1\n",
      "grameen: 1\n",
      "demonstrated: 1\n",
      "refer: 1\n",
      "biology: 1\n",
      "scientific: 1\n",
      "power: 1\n",
      "gained: 1\n",
      "world: 1\n",
      "constituting: 1\n",
      "angeles: 1\n",
      "range: 1\n",
      "duke: 1\n",
      "communication: 1\n",
      "due: 1\n",
      "appropriate: 1\n",
      "references: 1\n",
      "determine: 1\n",
      "additional: 1\n",
      "los: 1\n",
      "ares: 1\n",
      "house: 1\n",
      "head: 1\n",
      "boys: 1\n",
      "calico: 1\n",
      "rush: 1\n",
      "maximum: 1\n",
      "different: 1\n",
      "continuously: 1\n",
      "151: 1\n",
      "ag: 1\n",
      "certain: 1\n",
      "describe: 1\n",
      "general: 1\n",
      "engineering: 1\n",
      "accounting: 1\n",
      "reality: 1\n",
      "role: 1\n",
      "digital: 1\n",
      "department: 1\n",
      "wellesley: 1\n",
      "re-election: 1\n",
      "football: 1\n",
      "2014.: 1\n",
      "pool: 1\n",
      "age: 1\n",
      "dow: 1\n",
      "2006: 1\n",
      "2004: 1\n",
      "time: 1\n",
      "2009: 1\n",
      "requires: 1\n"
     ]
    }
   ],
   "source": [
    "full_text = getText(\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph.txt\")\n",
    "words = removeStopWords(full_text)\n",
    "sortWordFreq(wordFrequency(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onlyAscii(\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph.txt\",\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph-ascii.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text = open(\"C:/dev/EDO-Intern-Project/Kristen/nlp/data/appl-secfiling-director-paragraph-ascii.txt\",\"r\").readline()\n",
    "sent_tokens = tokenizer(clean_text)\n",
    "pos_tags = posTagger(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_text = cleanPosTagger(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnp_text = removeRepeats(key_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listDirectors = [\"Tim Cook\", \"Arthur Levinson\",\"James Bell\", \"Albert Gore\", \"Robert Iger\", \"Andrea Jung\",\"Ronald Sugar\",\"Susan Wagner\"]\n",
    "neo4j(nnp_text, listDirectors, \"C:/dev/EDO-Intern-Project/Kristen/nlp/data/cypher-commands-v2.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
